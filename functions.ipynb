{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNEmkfVRd8DFe2wK7UMKLbo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Funzioni"],"metadata":{"id":"T2gXzDpD4f-k"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn import metrics\n","from sklearn.model_selection import cross_val_score, train_test_split"],"metadata":{"id":"zbEAcyy_gi--"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","def fit_predict_print(train, test, target_columns, estimator):\n","  X_tr = train.drop(columns=target_columns)\n","  y_tr = train[target_columns]\n","  X_ts = test.drop(columns=target_columns)\n","  y_ts = test[target_columns]\n","\n","  return fit_predict_print_1(X_tr, X_ts, y_tr, y_ts, estimator)\n","\n","\n","def fit_predict_print_1(X_train, X_test, y_train, y_test, estimator):\n","  y_pred = estimator.fit(X_train, y_train).predict(X_test)\n","  print_accuracy(y_test, y_true, display_labels=estimator.classes_)\n","  return y_pred\n","\n","def print_accuracy(y_test, y_pred, display_labels=None):\n","  print('Accuracy:', metrics.accuracy_score(y_test, y_pred))\n","  cm = metrics.confusion_matrix(y_test, y_pred)\n","  print('Confusion matrix:\\n', cm)\n","  cmn = metrics.confusion_matrix(y_test, y_pred, normalize='true')\n","  ConfusionMatrixDisplay(cmn, display_labels=display_labels).plot()"],"metadata":{"id":"cq33n5rAgoma"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def balanced_subsample(X, y, subsample_size=1.0):\n","\n","    classes = y.unique()\n","    min_elems = y.value_counts().min()\n","\n","    use_elems = min_elems\n","    if subsample_size < 1:\n","        use_elems = int(min_elems * subsample_size)\n","\n","    Xb = pd.DataFrame()\n","    yb = pd.Series()\n","\n","    for c in classes:\n","      X_ = X[y == c]\n","      if X_.shape[0] > use_elems:\n","        X_ = X_.sample(use_elems)\n","\n","      yc = np.empty(use_elems)\n","      yc.fill(c)\n","      y_ = pd.Series(yc)\n","\n","      Xb = pd.concat([Xb, X_])\n","      yb = pd.concat([yb, y_])\n","\n","    return Xb, yb"],"metadata":{"id":"x-PHnt3DsA8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","\n","def one_hot_encode(dataset, columns, drop=None):\n","\n","  categories = []\n","  ret_columns = []\n","\n","  if isinstance(columns, str):\n","    columns = [columns]\n","  if (drop is not None) and (isinstance(drop, str)):\n","    drop = [drop]\n","\n","  for i in range(0, len(columns)):\n","    ctg = dataset.loc[:, columns[i]].unique().tolist()\n","    categories.append(ctg)\n","\n","    ctg_ = ctg.copy();\n","    if drop is not None:\n","      ctg_.remove(drop[i])\n","    ret_columns += ctg_\n","\n","  encoder = OneHotEncoder(categories=categories, drop=drop).fit(dataset[columns])\n","  ds = pd.DataFrame(encoder.transform(dataset[columns]).toarray(), columns=ret_columns)\n","\n","  return ds\n","\n","\n","def add_dummies(dataset, columns, drop_cat=None, drop_col=True):\n","  dummies = one_hot_encode(dataset, columns, drop_cat)\n","  if drop_col:\n","    ret = pd.concat([dataset.drop(columns=columns), dummies], axis=1)\n","  else:\n","    ret = pd.concat([dataset, dummies], axis=1)\n","  return ret"],"metadata":{"id":"YyKspM1csBjX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def xtab(rows_data, cols_data, normalize_rows=False):\n","  xtab = pd.crosstab(rows_data, cols_data)\n","  if normalize_rows:\n","    for i in xtab.index:\n","      xtab.loc[i] = xtab.loc[i] / (rows_data == i).sum()\n","    _ = sns.heatmap(xtab, vmin=0, vmax=1)\n","  else:\n","    _ = sns.heatmap(xtab)\n","  print(xtab)\n","  return xtab"],"metadata":{"id":"_8VOVsEqH7H6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def voting_classifier(estimators, X_train_list, y_train_list, X_test):\n","\n","    preds = np.asarray([clf.fit(X, y).predict(X_test) for clf, X, y in\n","                        zip(estimators, X_train_list, y_train_list)])\n","    modes = np.apply_along_axis(lambda x: np.bincount(x).argmax(),\n","                                axis=0, arr=preds)\n","\n","    return modes"],"metadata":{"id":"3h7dz8-K74x6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","\n","def models():\n","    models = []\n","    models.append(('LR'   , LogisticRegression()))\n","    models.append(('LDA'  , LinearDiscriminantAnalysis()))\n","    models.append(('KNN'  , KNeighborsClassifier()))\n","    models.append(('CART' , DecisionTreeClassifier()))\n","    models.append(('NB'   , GaussianNB()))\n","    models.append(('SVM'  , SVC(probability=True)))\n","    models.append(('AB'   , AdaBoostClassifier()))\n","    models.append(('GBM'  , GradientBoostingClassifier()))\n","    models.append(('RF'   , RandomForestClassifier()))\n","    models.append(('ET'   , ExtraTreesClassifier()))\n","    return models\n","\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","def cross_val_models(X, y, models=models(), num_folds=10, random_state=None,\n","                     scoring = 'accuracy'):\n","    names = []\n","    results = []\n","    for name, model in models:\n","        kfold = StratifiedKFold(n_splits=num_folds, random_state=random_state,\n","                                shuffle=True)\n","        cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring,\n","                                     n_jobs=-1)\n","        names.append(name)\n","        results.append(cv_results)\n","        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n","        print(msg)\n","\n","    return names, results\n","\n","\n","def boxplot_models_performance(X, y, models=models(), num_folds=10, random_state=None,\n","                     scoring = 'accuracy'):\n","  names, results = cross_val_models(X, y, models, num_folds, random_state, scoring)\n","  pd.DataFrame(np.array(results).T, columns=names).plot(kind='box')\n"],"metadata":{"id":"g2aGaHXYug7b"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ryKniNg-gar3"},"outputs":[],"source":["def train_test_classes_split(dataset, target_key, train_sizes, random_state=None):\n","  X_tr = pd.DataFrame()\n","  X_ts = pd.DataFrame()\n","  y_tr = pd.DataFrame()\n","  y_ts = pd.DataFrame()\n","\n","  for c in train_sizes.keys():\n","    ds = dataset[dataset[target_key] == c]\n","    y_c = ds[target_key]\n","    X_c = ds.drop(columns=target_key)\n","    X_tr_c, X_ts_c, y_tr_c, y_ts_c = train_test_split(X_c, y_c,\n","                                                      random_state=random_state,\n","                                                      train_size=train_sizes[c])\n","    X_tr = pd.concat([X_tr, X_tr_c])\n","    X_ts = pd.concat([X_ts, X_ts_c])\n","    y_tr = pd.concat([y_tr, y_tr_c])\n","    y_ts = pd.concat([y_ts, y_ts_c])\n","\n","  # print(X_tr_my.shape, X_ts_my.shape, y_tr_my.shape, y_ts_my.shape)\n","  return X_tr, X_ts, y_tr, y_ts"]}]}